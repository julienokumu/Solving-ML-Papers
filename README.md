Mistral7B Paper ✅ 	

Attention Is All You Need ✅

BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding ✅

AlexNet ✅
