Mistral7B Paper ✅ 				
Attention Is All You Need ✅
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding ✅
